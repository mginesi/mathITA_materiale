Fonti per il video [_una Nuova Teoria per l'Intelligenza Artificiale?_](https://youtu.be/iGi_9GDmV3k)

**link e fonti**

  - [AL] https://drive.google.com/file/d/1bFZpHBPr5l-cd-m2XBqQuLeRzQvfIGdW/view
  - [Cybenko 1989] [CYBENKO, George. Approximation by superpositions of a sigmoidal function. Mathematics of control, signals and systems, 1989, 2.4: 303-314.](https://link.springer.com/article/10.1007/BF02551274)
  - [Csaji et al. 2001] [CSÁJI, Balázs Csanád, et al. Approximation with artificial neural networks. Faculty of Sciences, Etvs Lornd University, Hungary, 2001, 24.48: 7.](https://www.researchgate.net/profile/Balazs-Csaji/publication/357888472_Approximation_with_Artificial_Neural_Networks/links/61e5b56c5779d35951b55282/Approximation-with-Artificial-Neural-Networks.pdf)
  - [Liu et al. 2024] [LIU, Ziming, et al. Kan: Kolmogorov-arnold networks. arXiv preprint arXiv:2404.19756, 2024.](https://arxiv.org/pdf/2404.19756)
  - [Yadav et al. 2015] [YADAV, Neha, et al. An introduction to neural network methods for differential equations. Berlin: Springer, 2015.](https://link.springer.com/chapter/10.1007/978-94-017-9816-7_2)
  - [Raschka 2015] RASCHKA, Sebastian. Python machine learning. Packt publishing ltd, 2015.
  - [Bishop 2006] [BISHOP, Christopher M.; NASRABADI, Nasser M. Pattern recognition and machine learning. New York: springer, 2006.](https://link.springer.com/book/10.1007/978-0-387-45528-0)
  - [Goodfellow et al. 2016] GOODFELLOW, Ian; BENGIO, Yoshua; COURVILLE, Aaron. Deep learning. MIT press, 2016.
  - [Heiberger et al. 2009] [HEIBERGER, Richard M., et al. Polynomial regression. R Through Excel: A Spreadsheet Interface for Statistics, Data Analysis, and Grapsics, 2009, 269-284.](https://link.springer.com/chapter/10.1007/978-1-4419-0052-4_11)
  - [Peterson 2009] [PETERSON, Leif E. K-nearest neighbor. Scholarpedia, 2009, 4.2: 1883.](http://scholarpedia.org/article/K-nearest_neighbor)
  - [Kramer et al. 2013] [KRAMER, Oliver; KRAMER, Oliver. K-nearest neighbors. Dimensionality reduction with unsupervised nearest neighbors, 2013, 13-23.](https://link.springer.com/chapter/10.1007/978-3-642-38652-7_2)
  - [Pisner et al. 2020] [PISNER, Derek A.; SCHNYER, David M. Support vector machine. In: Machine learning. Academic Press, 2020. p. 101-121.](https://www.sciencedirect.com/science/article/abs/pii/B9780128157398000067)
  - [Ginesi, Fiorini 2023] [GINESI, Michele; FIORINI, Paolo. Generalization of Auto-Regressive Hidden Markov Models to Non-Linear Dynamics and Unit Quaternion Observation Space. IEEE Robotics and Automation Letters, 2023.](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10202181)
  - [Yuanzhi et al. 2017] [LI, Yuanzhi; YUAN, Yang. Convergence analysis of two-layer neural networks with relu activation. Advances in neural information processing systems, 2017, 30.](https://proceedings.neurips.cc/paper_files/paper/2017/file/a96b65a721e561e1e3de768ac819ffbb-Paper.pdf)
  - [Juncai et al. 2018] [HE, Juncai, et al. ReLU deep neural networks and linear finite elements. arXiv preprint arXiv:1807.03973, 2018.](https://arxiv.org/pdf/1807.03973)
  - [Gu et al. 2018] [GU, Jiuxiang, et al. Recent advances in convolutional neural networks. Pattern recognition, 2018, 77: 354-377.](https://www.sciencedirect.com/science/article/pii/S0031320317304120)
  - [Li et al. 2021] [LI, Zewen, et al. A survey of convolutional neural networks: analysis, applications, and prospects. IEEE transactions on neural networks and learning systems, 2021, 33.12: 6999-7019.](https://ieeexplore.ieee.org/abstract/document/9451544)
  - [Blalock et al. 2020] [BLALOCK, Davis, et al. What is the state of neural network pruning?. Proceedings of machine learning and systems, 2020, 2: 129-146.](https://proceedings.mlsys.org/paper_files/paper/2020/file/6c44dc73014d66ba49b28d483a8f8b0d-Paper.pdf)
  - [Schmidt-Hieber 2021] [SCHMIDT-HIEBER, Johannes. The Kolmogorov–Arnold representation theorem revisited. Neural networks, 2021, 137: 119-126.](https://www.sciencedirect.com/science/article/pii/S0893608021000289  )
